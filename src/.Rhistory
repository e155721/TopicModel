## define function
medline <- function(file_name){
lines <- readLines(file_name)
medline_records <- list()
key <- 0
record <- 0
for(line in lines){
header <- sub(" {1,20}", "", substring(line, 1, 4))
value <- sub("^.{6}", "", line)
if(header == "" & value == ""){
next
}
else if(header == "PMID"){
record = record + 1
medline_records[[record]] <- list()
medline_records[[record]][header] <- value
}
else if(header == "" & value != ""){
medline_records[[record]][key] <- paste(medline_records[[record]][key], value)
}
else{
key <- header
if(is.null(medline_records[[record]][key][[1]])){
medline_records[[record]][key] <- value
}
else {
medline_records[[record]][key] <- paste(medline_records[[record]][key], value, sep=";")
}
}
}
return(medline_records)
}
## read Medline
fileVec <- list.files(file.path(getwd(), "..", "data","Papers"),
pattern=".txt",
full.names = T)
categoryVec <- list.files(file.path(getwd(), "..", "data", "Papers"),
pattern=".txt")
dataMed <- lapply(fileVec,medline)
# read in the libraries we're going to use
library(tidyverse) # general utility & workflow functions
library(tidytext) # tidy implimentation of NLP methods
library(topicmodels) # for LDA topic modelling
library(tm) # general text mining functions, making document term matrixes
library(SnowballC) # for stemming
# read in our data
reviews <- read_csv("../data/deceptive-opinion.csv")
# function to get & plot the most informative terms by a specificed number
# of topics, using LDA
top_terms_by_topic_LDA <- function(input_text, # should be a columm from a dataframe
plot = T, # return a plot? TRUE by defult
number_of_topics = 4) # number of topics (4 by default)
{
# create a corpus (type of object expected by tm) and document term matrix
Corpus <- Corpus(VectorSource(input_text)) # make a corpus object
DTM <- DocumentTermMatrix(Corpus) # get the count of words/document
# remove any empty rows in our document term matrix (if there are any
# we'll get an error when we try to run our LDA)
unique_indexes <- unique(DTM$i) # get the index of each unique value
DTM <- DTM[unique_indexes,] # get a subset of only those indexes
# preform LDA & get the words/topic in a tidy text format
lda <- LDA(DTM, k = number_of_topics, control = list(seed = 1234))
topics <- tidy(lda, matrix = "beta")
# get the top ten terms for each topic
top_terms <- topics  %>% # take the topics data frame and..
group_by(topic) %>% # treat each topic as a different group
top_n(10, beta) %>% # get the top 10 most informative words
ungroup() %>% # ungroup
arrange(topic, -beta) # arrange words in descending informativeness
# if the user asks for a plot (TRUE by default)
if(plot == T){
# plot the top ten terms for each topic in order
top_terms %>% # take the top terms
mutate(term = reorder(term, beta)) %>% # sort terms by beta value
ggplot(aes(term, beta, fill = factor(topic))) + # plot beta by theme
geom_col(show.legend = FALSE) + # as a bar plot
facet_wrap(~ topic, scales = "free") + # which each topic in a seperate plot
labs(x = NULL, y = "Beta") + # no x label, change y label
coord_flip() # turn bars sideways
}else{
# if the user does not request a plot
# return a list of sorted terms instead
return(top_terms)
}
}
# plot top ten terms in the hotel reviews by topic
top_terms_by_topic_LDA(reviews$text, number_of_topics = 2)
img
img()
# plot top ten terms in the hotel reviews by topic
img <- top_terms_by_topic_LDA(reviews$text, number_of_topics = 2)
pdf(file = "img.pdf")
plot(img)
dev.off()
readFile <- function(dir)
{
fileVec <- list.files(file.path(getwd(),dir),
pattern=".txt",
full.names=T)
len <- length(fileVec)
file <- list(1:len)
for (i in 1:len) {
file[i] <- read_file(paste(fileVec[i]))
}
return(file)
}
# read in our data
clean <- function(input_text, sw = c("a"))
{
# create a document term matrix to clean
reviewsCorpus <- Corpus(VectorSource(input_text))
reviewsDTM <- DocumentTermMatrix(reviewsCorpus)
# convert the document term matrix to a tidytext corpus
reviewsDTM_tidy <- tidy(reviewsDTM)
# I'm going to add my own custom stop words that I don't think will be
# very informative in hotel reviews
## custom_stop_words <- tibble(word = c("hotel", "room"))
custom_stop_words <- tibble(word = sw)
# remove stopwords
reviewsDTM_tidy_cleaned <- reviewsDTM_tidy %>% # take our tidy dtm and...
anti_join(stop_words, by = c("term" = "word")) %>% # remove English stopwords and...
anti_join(custom_stop_words, by = c("term" = "word")) # remove my custom stopwords
# stem the words (e.g. convert each word to its stem, where applicable)
reviewsDTM_tidy_cleaned <- reviewsDTM_tidy_cleaned %>%
mutate(stem = wordStem(term))
input_text <- reviewsDTM_tidy_cleaned$stem
return(input_text)
}
# read in the libraries we're going to use
library(tidyverse) # general utility & workflow functions
library(tidytext) # tidy implimentation of NLP methods
library(topicmodels) # for LDA topic modelling
library(tm) # general text mining functions, making document term matrixes
library(SnowballC) # for stemming
# function to get & plot the most informative terms by a specificed number
# of topics, using LDA
top_terms_by_topic_LDA <- function(input_text, # should be a columm from a dataframe
plot = T, # return a plot? TRUE by defult
user_model = NULL,
user_alpha = 0,
number_of_topics = 4) # number of topics (4 by default)
{
# create a corpus (type of object expected by tm) and document term matrix
Corpus <- Corpus(VectorSource(input_text)) # make a corpus object
DTM <- DocumentTermMatrix(Corpus) # get the count of words/document
# remove any empty rows in our document term matrix (if there are any
# we'll get an error when we try to run our LDA)
unique_indexes <- unique(DTM$i) # get the index of each unique value
DTM <- DTM[unique_indexes,] # get a subset of only those indexes
#preform LDA & get the words/topic in a tidy text format
if(class(user_model) == "LDA_VEM"  ) {
lda <- LDA(DTM, model = user_model,
control = list(seed = 1234, estimate.beta = TRUE, verbose = 1, initialize = "model"))
}
else if(user_alpha != 0) {
lda <- LDA(DTM, k = number_of_topics, control = list(seed = 1234, verbose = 1, alpha = user_alpha))
} else {
lda <- LDA(DTM, k = number_of_topics, control = list(seed = 1234, verbose = 1))
}
if(plot == F)
return(lda)
topics <- tidy(lda, matrix = "beta")
# get the top ten terms for each topic
top_terms <- topics  %>% # take the topics data frame and..
group_by(topic) %>% # treat each topic as a different group
top_n(10, beta) %>% # get the top 10 most informative words
ungroup() %>% # ungroup
arrange(topic, -beta) # arrange words in descending informativeness
# plot the top ten terms for each topic in order
top_terms %>% # take the top terms
mutate(term = reorder(term, beta)) %>% # sort terms by beta value
ggplot(aes(term, beta, fill = factor(topic))) + # plot beta by theme
geom_col(show.legend = FALSE) + # as a bar plot
facet_wrap(~ topic, scales = "free") + # which each topic in a seperate plot
labs(x = NULL, y = "Beta") + # no x label, change y label
coord_flip() # turn bars sideways
}
View(clean)
save.image("~/OkazakiLab/TopicModel/src/Untitled.RData")
x <- read.table("data.txt")
x
View(x)
input_text <- read_file("../data/PubMed/allergy_from-2010-01-01_121822.txt")
input_text <- clean(input_text)
x <- read.table("data2.txt")
198*2
198*3
582/3
x <- read.table("data.txt")
388/2
lda
source("execution.R")
source("execution.R")
source("execution.R")
c
lda
lda
lda
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
save.image("hoge.RData")
list_of_allergy_lda
list_of_allergy_lda
source("execution.R")
ls
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
list_of_psychiatry_lda
list_of_allergy_lda
list_of_allergy_lda
source("execution.R")
list_of_psychiatry_lda
list_of_psychiatry_lda
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
save.image("hoge.RData")
input_text
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
source("execution.R")
